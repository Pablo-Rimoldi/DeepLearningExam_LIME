{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/drive/1KSksZPsW6rNQfGW69wS8j5ietj3ayUkC\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "coQ7nfcyPZTN"
      },
      "source": [
        "Notes :\n",
        "- This notebook takes around 6 minutes to run.\n",
        "- I underlined the differences between the exam in the following code like this: <font color=\"red\">**CHANGE**</font>."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJOYXIX2foS0"
      },
      "source": [
        "# 0 - Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u1NRefM8VtU3"
      },
      "source": [
        "This section introduces the dataset loading process, utilizing the requests library to download the necessary data from the source."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WDWq8b-9b8us",
        "outputId": "7e0e619b-94bc-4d96-8208-c0157221be63"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import zipfile\n",
        "import pickle as pk\n",
        "\n",
        "url = \"https://frasca.di.unimi.it/MLDNN/input_data.zip\"\n",
        "\n",
        "response = requests.get(url)\n",
        "with open(\"data.zip\", \"wb\") as f:\n",
        "    f.write(response.content)\n",
        "\n",
        "with zipfile.ZipFile(\"data.zip\", 'r') as zip_ref:\n",
        "     zip_ref.extractall(\"unzipped_data\")\n",
        "\n",
        "with open(\"unzipped_data/input_data.pkl\", \"rb\") as f:\n",
        "     df = pk.load(f)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2FxJHYqoQjze"
      },
      "outputs": [],
      "source": [
        "%pip install tensorflow pydot graphviz\n",
        "\n",
        "import warnings\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import string\n",
        "import unicodedata\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import itertools\n",
        "import keras\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "from sklearn.metrics import accuracy_score, f1_score, mean_squared_error, confusion_matrix\n",
        "\n",
        "from keras.regularizers import l1, l2\n",
        "from keras.layers import (\n",
        "    Input, Dense, BatchNormalization, Dropout, Embedding,\n",
        "    Bidirectional, LSTM, Concatenate, Flatten\n",
        ")\n",
        "from keras.models import Model\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "from IPython.display import Image, display\n",
        "\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "scaler = MinMaxScaler()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "I suppress warnings to keep the output clean; mainly related to known deprecations in libraries that do not impact the result."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "sanity check, everything is working fine "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "reduced_df = df.copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zEZTewjCJMhr"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UUAV0PpkfrJD"
      },
      "source": [
        "# 2 - Input"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I0-cYhGUVnRx"
      },
      "source": [
        "This section in the exam was divided in two subparts:\n",
        "* How to (if) preprocess input data and which data would you retain/use;\n",
        "* Which is the input of the model, and how is it represented;"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "to avoid any kind of data leakage, I first divide into train, validation, and test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_df, temp_df = train_test_split(\n",
        "    reduced_df, test_size=0.20, random_state=42, shuffle=True\n",
        ")\n",
        "val_df, test_df = train_test_split(\n",
        "    temp_df, test_size=0.50, random_state=42, shuffle=True\n",
        ")\n",
        "print(len(train_df), len(val_df), len(test_df))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2.1 preprocessing:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.1.1 - Search Queries\n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "come ho detto durante l'esame questi vetori onehot encodati non hanno bisogno di ulteriore preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def extract_search_queries(df):\n",
        "    return np.stack(df['Search Queries'].values)\n",
        "\n",
        "train_hot_tensor = extract_search_queries(train_df)\n",
        "val_hot_tensor = extract_search_queries(val_df)\n",
        "test_hot_tensor = extract_search_queries(test_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NBd6q82WaaxU"
      },
      "source": [
        "### 2.1.3 - Timestamp "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As stated in the exam, I am going to:\n",
        "\n",
        "1. convert: minute, hour, day, month using a cyclic sine/cosine function\n",
        "2. convert the year into distance from the first istance\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9IibP1Z1xX4f",
        "outputId": "8cf5045a-81d2-4938-b284-5d78400416dc"
      },
      "outputs": [],
      "source": [
        "def transform_dates(df, min_year=None):\n",
        "    # Parse the timestamp with both date and time\n",
        "    df['Timestamp'] = pd.to_datetime(df['Timestamp'], format='%m/%d/%Y %H:%M')\n",
        "    # Extract components\n",
        "    df['Review_Day'] = df['Timestamp'].dt.day\n",
        "    df['Review_Month'] = df['Timestamp'].dt.month\n",
        "    df['Review_Hour'] = df['Timestamp'].dt.hour\n",
        "    df['Review_Minute'] = df['Timestamp'].dt.minute\n",
        "    df['Review_Year'] = df['Timestamp'].dt.year\n",
        "\n",
        "    # Cyclic encoding for day, month, hour, minute\n",
        "    df['Review_Day_sin'] = np.sin(2 * np.pi * df['Review_Day'] / 31)\n",
        "    df['Review_Day_cos'] = np.cos(2 * np.pi * df['Review_Day'] / 31)\n",
        "    df['Review_Month_sin'] = np.sin(2 * np.pi * df['Review_Month'] / 12)\n",
        "    df['Review_Month_cos'] = np.cos(2 * np.pi * df['Review_Month'] / 12)\n",
        "    df['Review_Hour_sin'] = np.sin(2 * np.pi * df['Review_Hour'] / 24)\n",
        "    df['Review_Hour_cos'] = np.cos(2 * np.pi * df['Review_Hour'] / 24)\n",
        "    df['Review_Minute_sin'] = np.sin(2 * np.pi * df['Review_Minute'] / 60)\n",
        "    df['Review_Minute_cos'] = np.cos(2 * np.pi * df['Review_Minute'] / 60)\n",
        "    if min_year is None:\n",
        "        min_year = df['Review_Year'].min()\n",
        "    df['Review_Year_Since'] = df['Review_Year'] - min_year\n",
        "    df.drop(columns=['Timestamp', 'Review_Day', 'Review_Month', 'Review_Hour', 'Review_Minute', 'Review_Year'], inplace=True)\n",
        "    return df, min_year\n",
        "\n",
        "train_df, min_year = transform_dates(train_df)\n",
        "val_df, _ = transform_dates(val_df, min_year)\n",
        "test_df, _ = transform_dates(test_df, min_year)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.1.4 Ad Topic Line"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "I clean the ad text by removing punctuation, stop words, and non-ASCII characters, and converting everything to lowercase"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "def preprocess_ad(text):\n",
        "    text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')    \n",
        "    text = text.replace('--', ' ')    \n",
        "    words = text.split()    \n",
        "    table = str.maketrans('', '', string.punctuation)\n",
        "    words = [w.translate(table) for w in words]    \n",
        "    words = [w.lower() for w in words if w.isalpha() and w.lower() not in stop_words]\n",
        "    return ' '.join(words)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To better understand the input data, I analyze the distribution of the number of words in each review after preprocessing. I compute basic statistics and plot a histogram to visualize how review lengths are spread."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for df_ in [train_df, val_df, test_df]:\n",
        "    df_[\"clean_text\"] = df_[\"Ad Topic Line\"].apply(preprocess_ad)\n",
        "    df_[\"ad_length\"] = df_[\"clean_text\"].apply(lambda x: len(x.split()))\n",
        "    df_[\"tokens\"] = df_[\"clean_text\"].str.split()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ad_length_stats = train_df[\"ad_length\"].describe()\n",
        "print(ad_length_stats)\n",
        "print(\"\\n\")\n",
        "quantiles = [0.50, 0.75, 0.90, 0.95, 0.98, 0.99, 1.00]\n",
        "for q in quantiles:\n",
        "    length_at_quantile = train_df[\"ad_length\"].quantile(q)\n",
        "    print(f\"Quantile {q*100:.0f}%: Reviews have length <= {length_at_quantile:.0f} words.\")\n",
        "\n",
        "plt.figure(figsize=(14, 7))\n",
        "sns.histplot(data=train_df, x=\"ad_length\", bins=50, kde=True,\n",
        "             label=\"Length distribution\", stat=\"density\")\n",
        "plt.axvline(train_df[\"ad_length\"].quantile(0.75), color='green', linestyle='--',\n",
        "            label=f'75th Quantile ({train_df[\"ad_length\"].quantile(0.75):.0f} words)')\n",
        "plt.axvline(train_df[\"ad_length\"].quantile(0.90), color='orange', linestyle='--',\n",
        "            label=f'90th Quantile ({train_df[\"ad_length\"].quantile(0.90):.0f} words)')\n",
        "plt.axvline(train_df[\"ad_length\"].quantile(0.95), color='red', linestyle='--',\n",
        "            label=f'95th Quantile ({train_df[\"ad_length\"].quantile(0.95):.0f} words)')\n",
        "plt.title('Distribution of Ad Topic Line with Highlighted Quantiles', fontsize=16)\n",
        "plt.xlabel('Number of Words per Ad Topic Line', fontsize=12)\n",
        "plt.ylabel('Density', fontsize=12)\n",
        "plt.legend()\n",
        "plt.xlim(0, train_df[\"ad_length\"].quantile(0.99))\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Based on the text preprocessing, a detailed analysis of the ad topic line lengths was conducted. The distribution and highlighted quantiles reveal several key insights:\n",
        "\n",
        "*   The ad topic lines are predominantly very short and concise, with the most frequent length being **3 words**, as shown by the highest peak in the distribution.\n",
        "*   The distribution is highly concentrated in a narrow range. This is confirmed by the quantiles, which show that **75% of ad topic lines have 3 words or fewer**.\n",
        "*   There is a very small tail to the distribution, with **95% of all ad topic lines containing 4 words or fewer**. This indicates a strong pattern of brevity for the vast majority of the dataset.\n",
        "\n",
        "per sicurezza di non perdere alcuna informazione, la lunghezza verrà messa al massimo: 5, la differenza di una sola parola non dovrebbe avere un impatto troppo significativo sulla complessità del modello, ma consenitrà di prendere appieno il contesto e il senso della frase.In questo caso per allenare il modello avrò bisogno di utilizzare dei caratteri token speciali chiamati padding, per fare in modo che anche le sequenxe più brevi di 5 caratteri possano arrivare a quella lunghezza, questi caratteri in fase poi di training dei pesi verrano ignorati per questultimo scopo. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ad_all_train_words = [word for tokens in train_df['tokens'] for word in tokens]\n",
        "ad_unique_words = sorted(list(set(ad_all_train_words)))\n",
        "\n",
        "ad_word_index = {word: i + 2 for i, word in enumerate(ad_unique_words)}\n",
        "ad_word_index[\"<OOV>\"] = 1\n",
        "AD_MAX_LEN = 5\n",
        "AD_VOCAB_SIZE = len(ad_unique_words) + 2\n",
        "\n",
        "\n",
        "def ad_text_to_sequence(tokens, word_index_dict):\n",
        "    seq = [word_index_dict.get(word, word_index_dict[\"<OOV>\"]) for word in tokens]\n",
        "    return seq\n",
        "\n",
        "ad_train_sequences = [ad_text_to_sequence(tokens, ad_word_index) for tokens in train_df['tokens']]\n",
        "ad_val_sequences = [ad_text_to_sequence(tokens, ad_word_index) for tokens in val_df['tokens']]\n",
        "ad_test_sequences = [ad_text_to_sequence(tokens, ad_word_index) for tokens in test_df['tokens']]\n",
        "\n",
        "train_ad_seqs = pad_sequences(ad_train_sequences, maxlen=AD_MAX_LEN, padding='post', truncating='post')\n",
        "val_ad_seqs = pad_sequences(ad_val_sequences, maxlen=AD_MAX_LEN, padding='post', truncating='post')\n",
        "test_ad_seqs = pad_sequences(ad_test_sequences, maxlen=AD_MAX_LEN, padding='post', truncating='post')\n",
        "\n",
        "print(\"Shape of final training sequences tensor:\", train_ad_seqs.shape)\n",
        "print(\"Example of a processed sequence:\", train_ad_seqs[29])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.1.5 Country"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def preprocess_location(country):\n",
        "    # Normalize unicode\n",
        "    country = unicodedata.normalize('NFKD', country).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
        "    country = country.replace('--', ' ')\n",
        "    # Remove punctuation except spaces\n",
        "    table = str.maketrans('', '', string.punctuation.replace(' ', ''))\n",
        "    country = country.translate(table)\n",
        "    country = country.lower()\n",
        "    # Remove extra spaces\n",
        "    country = ' '.join(country.split())\n",
        "    # Join multi-word country names with no separator (single word)\n",
        "    country = country.replace(' ', '')\n",
        "    # Only allow alphabetic (no numbers or other chars)\n",
        "    if country.isalpha() and country:\n",
        "        return country\n",
        "    else:\n",
        "        return ''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for df_ in [train_df, val_df, test_df]:\n",
        "    df_[\"clean_country\"] = df_[\"Country\"].apply(preprocess_location)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_word_index(words):\n",
        "    \"\"\"\n",
        "    Create a word-to-index dictionary for a list of words.\n",
        "    Indexing starts at 2, with 1 reserved for <OOV>.\n",
        "    \"\"\"\n",
        "    unique_words = sorted(set(words))\n",
        "    word_index = {word: i + 2 for i, word in enumerate(unique_words)}\n",
        "    word_index[\"<OOV>\"] = 1\n",
        "    return word_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Create word index for clean_country using only train_df to avoid data leakage\n",
        "country_word_index = create_word_index(train_df[\"clean_country\"])\n",
        "COUNTRY_VOCAB_SIZE = len(country_word_index) + 1\n",
        "\n",
        "def country_to_index(country):\n",
        "    return country_word_index.get(country, country_word_index[\"<OOV>\"])\n",
        "\n",
        "train_country_tensor = train_df[\"clean_country\"].apply(country_to_index).values\n",
        "val_country_tensor = val_df[\"clean_country\"].apply(country_to_index).values\n",
        "test_country_tensor = test_df[\"clean_country\"].apply(country_to_index).values\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.1.6 city"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for df_ in [train_df, val_df, test_df]:\n",
        "    df_[\"clean_city\"] = df_[\"City\"].apply(preprocess_location)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create word index for clean_city using only train_df to avoid data leakage\n",
        "city_word_index = create_word_index(train_df[\"clean_city\"])\n",
        "CITY_VOCAB_SIZE = len(city_word_index) + 1 \n",
        "\n",
        "def city_to_index(city):\n",
        "    return city_word_index.get(city, city_word_index[\"<OOV>\"])\n",
        "\n",
        "train_city_tensor = train_df[\"clean_city\"].apply(city_to_index).values\n",
        "val_city_tensor = val_df[\"clean_city\"].apply(city_to_index).values\n",
        "test_city_tensor = test_df[\"clean_city\"].apply(city_to_index).values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.1.7 - Numerical group of features: Age,  Area Income,  Daily Internet Usage, Male, Daily Time Spent on Site, converted timestamp "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "numeric_cols = [\n",
        "    'Age', 'Area Income', 'Daily Internet Usage', 'Male', 'Daily Time Spent on Site',\n",
        "    'Review_Day_sin', 'Review_Day_cos', 'Review_Month_sin', 'Review_Month_cos',\n",
        "    'Review_Hour_sin', 'Review_Hour_cos', 'Review_Minute_sin', 'Review_Minute_cos', 'Review_Year_Since'\n",
        "]\n",
        "\n",
        "train_nums_tensor = scaler.fit_transform(train_df[numeric_cols])\n",
        "val_nums_tensor   = scaler.transform(val_df[numeric_cols])\n",
        "test_nums_tensor  = scaler.transform(test_df[numeric_cols])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tjICOJlGQAIz"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2.2. Input of the model "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The model architecture is designed to accept five distinct and parallel inputs, each representing a different type of information extracted from the original data. This multi-input architecture allows the model to learn specific representations for each data type before merging them for the final prediction.\n",
        "\n",
        "The five input tensors are summarized below, showing the shape and a brief description of their content. These tensors represent the textual, categorical, and numerical data, respectively.\n",
        "\n",
        "As outlined in the exam, the textual data input will be processed either by an embedding layer or an LSTM layer. The other two inputs (categorical and numerical), which are here separated just for clarity, will be concatenated with the output representation from the embeddign layers and the lstm layer. This combined vector will then serve as the input for the subsequent fully-connected deep neural network."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "print(\"\\n1. TEXTUAL INPUT -Ad Topic Line (Padded Token Sequences)\")\n",
        "print(f\"   - Training tensor shape: {train_ad_seqs.shape}\")\n",
        "print(f\"   - Validation tensor shape: {val_ad_seqs.shape}\")\n",
        "print(f\"   - Test tensor shape: {test_ad_seqs.shape}\")\n",
        "\n",
        "print(\"\\n2. TEXTUAL INPUT -Country (integer index)\")\n",
        "print(f\"   - Training tensor shape: {train_country_tensor.shape}\")\n",
        "print(f\"   - Validation tensor shape: {val_country_tensor.shape}\")\n",
        "print(f\"   - Test tensor shape: {test_country_tensor.shape}\")\n",
        "\n",
        "print(\"\\n3. TEXTUAL INPUT -City (integer index)\")\n",
        "print(f\"   - Training tensor shape: {train_city_tensor.shape}\")\n",
        "print(f\"   - Validation tensor shape: {val_city_tensor.shape}\")\n",
        "print(f\"   - Test tensor shape: {test_city_tensor.shape}\")\n",
        "\n",
        "print(\"\\n4. CATEGORICAL INPUT (One-Hot Encoded)\")\n",
        "print(f\"   - Training tensor shape: {train_hot_tensor.shape}\")\n",
        "print(f\"   - Validation tensor shape: {val_hot_tensor.shape}\")\n",
        "print(f\"   - Test tensor shape: {test_hot_tensor.shape}\")\n",
        "\n",
        "print(\"\\n5. NUMERICAL INPUT (Normalized Features)\")\n",
        "print(f\"   - Training tensor shape: {train_nums_tensor.shape}\")\n",
        "print(f\"   - Validation tensor shape: {val_nums_tensor.shape}\")\n",
        "print(f\"   - Test tensor shape: {test_nums_tensor.shape}\")\n",
        "print(f\"   - Included columns: {numeric_cols}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-2yUKMrkaWn1"
      },
      "source": [
        "# 3 - 4 (OUTPUT - LOSS - MODEL CONFIGURATION)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IOw9bozw7a-L"
      },
      "source": [
        "This section represents the following three parts:\n",
        "\n",
        "3. OUTPUT/LOSS: How would you design the output layer and why; Which loss function would you use to train your model and\n",
        "why;\n",
        "4. MODEL CONFIGURATION\n",
        "  * Model overall composition/pipeline,\n",
        "  * model optimization;"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3.1 Output:\n",
        "\n",
        "- label preprocessing: For the label in this notebook I will not manually convert the label into their one not encoded version, I will leave as integer because I will use the sparse categorical cross-entropy, but still we know that this is happening under the hood.\n",
        "\n",
        "- Output layer: Come spiegato in esame, We use a **two unit softmax output** model, because the LIME package needs a probability distribution as prediction\n",
        "\n",
        "- loss: since I want to match my output probability distribution with the ground truth, I will need a sparse categorical cross-entropy to minimize the distance of the two probability distributions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_labels = train_df[\"Clicked on Ad\"]\n",
        "val_labels = val_df[\"Clicked on Ad\"]\n",
        "test_labels = test_df[\"Clicked on Ad\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3.2 LOSS - MODEL CONFIGURATION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ILhjDBpq5k5S"
      },
      "outputs": [],
      "source": [
        "\n",
        "def create_model(\n",
        "    country_vocab_size,\n",
        "    city_vocab_size,\n",
        "    ad_vocab_size,\n",
        "    query_onehot_dim,\n",
        "    numeric_features,\n",
        "    ad_max_len=5,\n",
        "    country_max_len=1,\n",
        "    city_max_len=1,\n",
        "    ad_embedding_dim=32,\n",
        "    ad_lstm_units=16,\n",
        "    country_embedding_dim=8,\n",
        "    city_embedding_dim=8,\n",
        "    hidden_layer_sizes=[256, 128, 64, 32],\n",
        "    dropout_rate=0.1,\n",
        "    weight_reg=l2(0.01)\n",
        "):\n",
        "    country_input = Input(shape=(country_max_len,), name='country_input')\n",
        "    city_input = Input(shape=(city_max_len,), name='city_input')\n",
        "    ad_input = Input(shape=(ad_max_len,), name='ad_input')\n",
        "    query_input = Input(shape=(query_onehot_dim,), name='query_input')\n",
        "    numeric_input = Input(shape=(numeric_features,), name='numeric_input')\n",
        "\n",
        "\n",
        "    x_country_text = Embedding(input_dim=country_vocab_size,\n",
        "                       output_dim=country_embedding_dim,\n",
        "                       input_length=country_max_len)(country_input)\n",
        "    x_country_text = Flatten()(x_country_text)\n",
        "\n",
        "\n",
        "    \n",
        "    x_city_text = Embedding(input_dim=city_vocab_size,\n",
        "                       output_dim=city_embedding_dim,\n",
        "                       input_length=city_max_len)(city_input)\n",
        "    x_city_text = Flatten()(x_city_text)\n",
        "\n",
        "\n",
        "    x_ad_text = Embedding(input_dim=ad_vocab_size,\n",
        "                       output_dim=ad_embedding_dim,\n",
        "                       input_length=ad_max_len,\n",
        "                       mask_zero=True)(ad_input)\n",
        "    x_ad_text = Bidirectional(LSTM(ad_lstm_units,\n",
        "                                activation='tanh',\n",
        "                                recurrent_activation='sigmoid',\n",
        "                                dropout=dropout_rate,\n",
        "                                recurrent_dropout=dropout_rate,\n",
        "                                kernel_initializer='glorot_uniform', \n",
        "                                recurrent_initializer='glorot_uniform'\n",
        "                               ))(x_ad_text)\n",
        "\n",
        "    x = Concatenate()([x_ad_text, x_country_text, x_city_text, query_input, numeric_input])\n",
        "\n",
        "\n",
        "    for i, size in enumerate(hidden_layer_sizes, start=1):\n",
        "        x = Dense(size,\n",
        "                  activation='relu',\n",
        "                  kernel_initializer='he_uniform',\n",
        "                  kernel_regularizer=weight_reg,\n",
        "                  name=f'dense_{i}')(x)\n",
        "        x = BatchNormalization(name=f'bn_{i}')(x)\n",
        "        x = Dropout(dropout_rate, name=f'dropout_{i}')(x)\n",
        "\n",
        "    output = Dense(2, activation=\"softmax\")(x)\n",
        "\n",
        "    return Model(inputs=[country_input, city_input, ad_input, query_input, numeric_input],\n",
        "                 outputs=[output])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5 - Hyperparametr optimization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "param_grid = {\n",
        "    'learning_rate':     [2e-3, 5e-3, 1e-2],\n",
        "    'batch_size':        [64, 128, 256],\n",
        "    'epochs':            [5, 10, 20, 25],\n",
        "    'dropout_rate':      [0.2, 0.3, 0.4, 0.5],\n",
        "    'weight_reg':        [l2(1e-4), l2(1e-3), l2(1e-2)],\n",
        "    'ad_embedding_dim':  [16, 32, 64],\n",
        "    'ad_lstm_units':     [8, 16, 32],\n",
        "    'country_embedding_dim': [4, 8, 16],\n",
        "    'city_embedding_dim':    [4, 8, 16],\n",
        "    'optimizer':         ['adam'],\n",
        "    'hidden_layer_sizes': [\n",
        "        [256, 128, 64, 32],\n",
        "        [128, 64, 32],\n",
        "        [64, 32]\n",
        "    ]\n",
        "}\n",
        "num_samples = 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- We are tuning parameters like learning_rate, dropout_rate, and loss_weight_score, which have a significant influence on model convergence and generalization without drastically increasing training time per trial. More computationally expensive parameters, such as the number of LSTM layers or a much wider range for embedding_dim, have been intentionally kept fixed or limited. This focused approach allows for an efficient yet meaningful optimization process within the available computational budget.\n",
        "\n",
        "- Due to time constraints, the following random search is limited to num_samples = 3. This serves as a proof of concept for the tuning methodology rather than an exhaustive search for an optimal model. For the final evaluation, a pre-vetted, well performing configuration is used to ensure a meaningful analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def random_search(param_grid, samples=5):\n",
        "    \"\"\"\n",
        "    Esegue una ricerca casuale di iperparametri per il modello di classificazione.\n",
        "    NOTA: Nonostante il nome, questa funzione è stata adattata per un modello\n",
        "    single-task e si basa su variabili di dati definite globalmente.\n",
        "    \"\"\"\n",
        "    combos = list(itertools.product(*param_grid.values()))\n",
        "    num_to_sample = min(samples, len(combos))\n",
        "    sampled_combos = random.sample(combos, num_to_sample)\n",
        "    configs = [dict(zip(param_grid.keys(), c)) for c in sampled_combos]\n",
        "\n",
        "    best_model = {\n",
        "        'f1_score': (0, None),\n",
        "        'accuracy': (0, None)\n",
        "    }\n",
        "\n",
        "    # Prepara i dizionari di input usando i nomi delle variabili forniti\n",
        "    train_inputs = {\n",
        "        'country_input': train_country_tensor,\n",
        "        'city_input': train_city_tensor,\n",
        "        'ad_input': train_ad_seqs,\n",
        "        'query_input': train_hot_tensor,\n",
        "        'numeric_input': train_nums_tensor\n",
        "    }\n",
        "    val_inputs = {\n",
        "        'country_input': val_country_tensor,\n",
        "        'city_input': val_city_tensor,\n",
        "        'ad_input': val_ad_seqs,\n",
        "        'query_input': val_hot_tensor,\n",
        "        'numeric_input': val_nums_tensor\n",
        "    }\n",
        "\n",
        "    for idx, cfg in enumerate(configs):\n",
        "        K.clear_session()\n",
        "        print(f\"\\n{'='*10} Training config {idx+1}/{len(configs)} {'='*10}\")\n",
        "        print(\"Config:\", cfg)\n",
        "        \n",
        "        # 1. Creazione del Modello\n",
        "        # Le dimensioni sono ottenute dinamicamente dalle shape dei tensori di input\n",
        "        model = create_model(\n",
        "            country_vocab_size=COUNTRY_VOCAB_SIZE,\n",
        "            city_vocab_size=CITY_VOCAB_SIZE,\n",
        "            ad_vocab_size=AD_VOCAB_SIZE,\n",
        "            query_onehot_dim=train_hot_tensor.shape[1],\n",
        "            numeric_features=train_nums_tensor.shape[1],\n",
        "            ad_max_len=train_ad_seqs.shape[1],\n",
        "            country_max_len=1, #train_country_tensor.shape[1],\n",
        "            city_max_len=1, #train_city_tensor.shape[1],\n",
        "            ad_embedding_dim=cfg['ad_embedding_dim'],\n",
        "            ad_lstm_units=cfg['ad_lstm_units'],\n",
        "            country_embedding_dim=cfg['country_embedding_dim'],\n",
        "            city_embedding_dim=cfg['city_embedding_dim'],\n",
        "            hidden_layer_sizes=cfg['hidden_layer_sizes'],\n",
        "            dropout_rate=cfg['dropout_rate'],\n",
        "            weight_reg=cfg['weight_reg']\n",
        "        )\n",
        "\n",
        "        # 2. Compilazione per classificazione single-task\n",
        "        Optimizer = keras.optimizers.Adam if cfg['optimizer'] == 'adam' else keras.optimizers.RMSprop\n",
        "        model.compile(\n",
        "            loss='sparse_categorical_crossentropy',\n",
        "            optimizer=Optimizer(learning_rate=cfg['learning_rate']),\n",
        "            metrics=['accuracy']\n",
        "        )\n",
        "\n",
        "        # 3. Addestramento del modello\n",
        "        history = model.fit(\n",
        "            train_inputs,\n",
        "            train_labels, # Assumendo che le etichette di training si chiamino così\n",
        "            epochs=cfg['epochs'],\n",
        "            batch_size=cfg['batch_size'],\n",
        "            validation_data=(val_inputs, val_labels), # E quelle di validazione così\n",
        "            verbose=1,\n",
        "            callbacks=[\n",
        "                keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "            ]\n",
        "        )\n",
        "        \n",
        "        # 4. Valutazione\n",
        "        pred_probs = model.predict(val_inputs, verbose=0)\n",
        "        # This is correct: convert the model's 2D probability output to 1D predicted labels\n",
        "        pred_labels = np.argmax(pred_probs, axis=1) \n",
        "\n",
        "        true_labels = val_labels\n",
        "        acc = accuracy_score(true_labels, pred_labels)\n",
        "        f1 = f1_score(true_labels, pred_labels, average='weighted')\n",
        "        \n",
        "        print(\"\\nEvaluation metrics:\")\n",
        "        print(f\"  Accuracy = {acc:.4f}, F1-Score = {f1:.4f}\\n\")\n",
        "        # Aggiunto zero_division=0 per evitare warning se una classe non ha predizioni\n",
        "        print(classification_report(true_labels, pred_labels, zero_division=0))\n",
        "        # 5. Aggiornamento dei migliori risultati\n",
        "        if f1 > best_model['f1_score'][0]:\n",
        "            best_model['f1_score'] = (f1, cfg)\n",
        "        if acc > best_model['accuracy'][0]:\n",
        "            best_model['accuracy'] = (acc, cfg)\n",
        "\n",
        "    print(\"\\n{'='*15} Best Results Summary {'='*15}\")\n",
        "    print(f\"Best model (by F1-Score): {best_model['f1_score'][0]:.4f} -> Config: {best_model['f1_score'][1]}\")\n",
        "    print(f\"Best model (by Accuracy): {best_model['accuracy'][0]:.4f} -> Config: {best_model['accuracy'][1]}\")\n",
        "    \n",
        "    return best_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_results = random_search(param_grid)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The following configuration was identified as a well performing candidate during more extensive, offline experiments. For reproducibility within this notebook, we will use this specific configuration for final training and evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V3Xv4zQbTTYA"
      },
      "outputs": [],
      "source": [
        "best_learning_rate = 0.005\n",
        "best_batch_size = 64\n",
        "best_epochs = 20\n",
        "best_dropout_rate = 0.4\n",
        "best_weight_reg = keras.regularizers.l2(1e-2)\n",
        "best_ad_embedding_dim = 16\n",
        "best_ad_lstm_units = 16\n",
        "best_country_embedding_dim = 16\n",
        "best_city_embedding_dim = 4\n",
        "best_optimizer = 'adam'\n",
        "best_hidden_layer_sizes = [256, 128, 64, 32]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "KL2fLtnT_9mC",
        "outputId": "42a51041-cacb-4cf9-e424-3b3f067bc2f5"
      },
      "outputs": [],
      "source": [
        "K.clear_session()\n",
        "\n",
        "best_model = create_model(\n",
        "    country_vocab_size=COUNTRY_VOCAB_SIZE,\n",
        "    city_vocab_size=CITY_VOCAB_SIZE,\n",
        "    ad_vocab_size=AD_VOCAB_SIZE,\n",
        "    query_onehot_dim=train_hot_tensor.shape[1],\n",
        "    numeric_features=train_nums_tensor.shape[1],\n",
        "    ad_max_len=train_ad_seqs.shape[1],\n",
        "    country_max_len=1,  # train_country_tensor.shape[1],\n",
        "    city_max_len=1,     # train_city_tensor.shape[1],\n",
        "    ad_embedding_dim=best_ad_embedding_dim,\n",
        "    ad_lstm_units=best_ad_lstm_units,\n",
        "    country_embedding_dim=best_country_embedding_dim,\n",
        "    city_embedding_dim=best_city_embedding_dim,\n",
        "    hidden_layer_sizes=best_hidden_layer_sizes,\n",
        "    dropout_rate=best_dropout_rate,\n",
        "    weight_reg=best_weight_reg\n",
        ")\n",
        "\n",
        "Optimizer = keras.optimizers.Adam if best_optimizer == 'adam' else keras.optimizers.RMSprop\n",
        "\n",
        "best_model.compile(\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    optimizer=Optimizer(learning_rate=best_learning_rate),\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "train_inputs = {\n",
        "    'country_input': train_country_tensor,\n",
        "    'city_input': train_city_tensor,\n",
        "    'ad_input': train_ad_seqs,\n",
        "    'query_input': train_hot_tensor,\n",
        "    'numeric_input': train_nums_tensor\n",
        "}\n",
        "val_inputs = {\n",
        "    'country_input': val_country_tensor,\n",
        "    'city_input': val_city_tensor,\n",
        "    'ad_input': val_ad_seqs,\n",
        "    'query_input': val_hot_tensor,\n",
        "    'numeric_input': val_nums_tensor\n",
        "}\n",
        "\n",
        "history = best_model.fit(\n",
        "            train_inputs,\n",
        "            train_labels, \n",
        "            epochs=best_epochs,\n",
        "            batch_size=best_batch_size,\n",
        "            validation_data=(val_inputs, val_labels),\n",
        "            verbose=1,\n",
        "            callbacks=[\n",
        "                keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\"*60)\n",
        "print(\"MODEL COMPOSITION REPORT\")\n",
        "print(\"=\"*60)\n",
        "best_model.summary()\n",
        "\n",
        "\n",
        "print(\"\\n\\n\" + \"=\"*60)\n",
        "print(\"MODEL ARCHITECTURE PLOT\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Generate the plot and save it to a file\n",
        "\n",
        "try:\n",
        "    plot_model(\n",
        "    best_model,\n",
        "    to_file='model_architecture.png',\n",
        "    show_shapes=True,           # Display shape information\n",
        "    show_layer_names=True,      # Display layer names\n",
        "    show_dtype=False,           # Don't show data types\n",
        "    show_layer_activations=True )# Show activation functions\n",
        "    display(Image('model_architecture.png'))\n",
        "except:\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The following plots visualize the model's performance during training for the and classification tasks. We analyze the loss key metrics (Accuracy) for both training and validation sets. This allows us to assess model convergence, diagnose potential overfitting, and evaluate the effectiveness of our training strategy across epochs.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_training_history(history):\n",
        "    # For a standard MLP with a single output and single loss/accuracy\n",
        "    train_loss = history.history.get('loss', [])\n",
        "    val_loss = history.history.get('val_loss', [])\n",
        "    train_acc = history.history.get('accuracy', [])\n",
        "    val_acc = history.history.get('val_accuracy', [])\n",
        "\n",
        "    epochs = range(1, len(train_loss) + 1)\n",
        "\n",
        "    fig, axs = plt.subplots(1, 2, figsize=(14, 6))\n",
        "    fig.suptitle('Training and Validation History', fontsize=20)\n",
        "\n",
        "    # Plot Loss\n",
        "    axs[0].plot(epochs, train_loss, 'bo-', label='Training Loss')\n",
        "    axs[0].plot(epochs, val_loss, 'ro-', label='Validation Loss')\n",
        "    axs[0].set_title('Loss')\n",
        "    axs[0].set_xlabel('Epochs')\n",
        "    axs[0].set_ylabel('Loss')\n",
        "    axs[0].legend()\n",
        "    axs[0].grid(True)\n",
        "\n",
        "    if train_acc and val_acc:\n",
        "        axs[1].plot(epochs, train_acc, 'bo-', label='Training Accuracy')\n",
        "        axs[1].plot(epochs, val_acc, 'ro-', label='Validation Accuracy')\n",
        "        axs[1].set_title('Accuracy')\n",
        "        axs[1].set_xlabel('Epochs')\n",
        "        axs[1].set_ylabel('Accuracy')\n",
        "        axs[1].legend()\n",
        "        axs[1].grid(True)\n",
        "    else:\n",
        "        axs[1].set_visible(False)\n",
        "\n",
        "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
        "    plt.show()\n",
        "\n",
        "plot_training_history(history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 6 - MODEL EVALUATION"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This section is dedicated to the final evaluation of the best-performing model, identified through the hyperparameter optimization process.\n",
        "\n",
        "The evaluation is conducted on the **unseen test set** to provide an unbiased estimate of the model's generalization capabilities. The process follows the plan outlined in the exam:\n",
        "1.  Evaluate the classification task.\n",
        "2.  Visualize the results to gain deeper insights (e.g., Confusion Matrix and performance plots)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, classification_report\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Predict on test set\n",
        "test_pred_probs = best_model.predict(\n",
        "    {\n",
        "        'country_input': test_country_tensor,\n",
        "        'city_input': test_city_tensor,\n",
        "        'ad_input': test_ad_seqs,\n",
        "        'query_input': test_hot_tensor,\n",
        "        'numeric_input': test_nums_tensor\n",
        "    },\n",
        "    verbose=0\n",
        ")\n",
        "test_pred_labels = np.argmax(test_pred_probs, axis=1)\n",
        "y_true = test_labels\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_true, test_pred_labels)\n",
        "# Plot Confusion Matrix\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# Classification Report\n",
        "report = classification_report(y_true, test_pred_labels)\n",
        "print(\"Classification Report:\\n\", report)\n",
        "\n",
        "\n",
        "# Accuracy Score\n",
        "acc = accuracy_score(y_true, test_pred_labels)\n",
        "print(\"Accuracy Score:\", acc)\n",
        "\n",
        "# F1 Score\n",
        "f1 = f1_score(y_true, test_pred_labels, average='weighted')\n",
        "print(\"F1 Score (weighted):\", f1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 6 - MODEL INTERPRETATION (LIME )"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
