{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Machine Learning, Artificial Neural Networks and Deep Learning - Part 2\n",
        "### Exam Solution\n",
        "\n",
        "**Student:** Pablo Rimoldi\n",
        "**ID Number:** 535345"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJOYXIX2foS0"
      },
      "source": [
        "# 0 - Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u1NRefM8VtU3"
      },
      "source": [
        "This section introduces the dataset loading process, utilizing the requests library to download the necessary data from the source."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WDWq8b-9b8us",
        "outputId": "7e0e619b-94bc-4d96-8208-c0157221be63"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import zipfile\n",
        "import pickle as pk\n",
        "\n",
        "url = \"https://frasca.di.unimi.it/MLDNN/input_data.zip\"\n",
        "\n",
        "response = requests.get(url)\n",
        "with open(\"data.zip\", \"wb\") as f:\n",
        "    f.write(response.content)\n",
        "\n",
        "with zipfile.ZipFile(\"data.zip\", 'r') as zip_ref:\n",
        "     zip_ref.extractall(\"unzipped_data\")\n",
        "\n",
        "with open(\"unzipped_data/input_data.pkl\", \"rb\") as f:\n",
        "     df = pk.load(f)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2FxJHYqoQjze"
      },
      "outputs": [],
      "source": [
        "%pip install tensorflow pydot graphviz lime\n",
        "\n",
        "import os\n",
        "import random\n",
        "import string\n",
        "import itertools\n",
        "import unicodedata\n",
        "import warnings\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import plot_model, to_categorical\n",
        "\n",
        "import keras\n",
        "from keras.regularizers import l1, l2\n",
        "from keras.layers import (\n",
        "    Input, Dense, BatchNormalization, Dropout, Embedding,\n",
        "    Bidirectional, LSTM, Concatenate, Flatten\n",
        ")\n",
        "from keras.models import Model\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, f1_score, mean_squared_error, confusion_matrix, classification_report\n",
        ")\n",
        "\n",
        "from IPython.display import Image, display\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "scaler = MinMaxScaler()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "I suppress warnings to keep the output clean; mainly related to known deprecations in libraries that do not impact the result."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "sanity check, everything is working fine "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.head"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zEZTewjCJMhr"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UUAV0PpkfrJD"
      },
      "source": [
        "# 2 - Input"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I0-cYhGUVnRx"
      },
      "source": [
        "This section in the exam was divided in two subparts:\n",
        "* How to (if) preprocess input data and which data would you retain/use;\n",
        "* Which is the input of the model, and how is it represented;"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "to avoid any kind of data leakage, I first divide into train, validation, and test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_df, temp_df = train_test_split(\n",
        "    df, test_size=0.20, random_state=42, shuffle=True\n",
        ")\n",
        "val_df, test_df = train_test_split(\n",
        "    temp_df, test_size=0.50, random_state=42, shuffle=True\n",
        ")\n",
        "print(len(train_df), len(val_df), len(test_df))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2.1 preprocessing:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.1.1 - Search Queries\n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As I said during the exam, these vectors once one-hot encoded do not need any further preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def extract_search_queries(df):\n",
        "    return np.stack(df['Search Queries'].values)\n",
        "\n",
        "train_hot_tensor = extract_search_queries(train_df)\n",
        "val_hot_tensor = extract_search_queries(val_df)\n",
        "test_hot_tensor = extract_search_queries(test_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NBd6q82WaaxU"
      },
      "source": [
        "### 2.1.3 - Timestamp "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As stated in the exam, I am going to:\n",
        "\n",
        "1. convert: minute, hour, day, month using a cyclic sine/cosine function\n",
        "2. convert the year into distance from the first istance\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9IibP1Z1xX4f",
        "outputId": "8cf5045a-81d2-4938-b284-5d78400416dc"
      },
      "outputs": [],
      "source": [
        "def transform_dates(df, min_year=None):\n",
        "    df['Timestamp'] = pd.to_datetime(df['Timestamp'], format='%m/%d/%Y %H:%M') # Parse the timestamp with both date and time\n",
        "\n",
        "    # Extract components\n",
        "    df['Day'] = df['Timestamp'].dt.day\n",
        "    df['Month'] = df['Timestamp'].dt.month\n",
        "    df['Hour'] = df['Timestamp'].dt.hour\n",
        "    df['Minute'] = df['Timestamp'].dt.minute\n",
        "    df['Year'] = df['Timestamp'].dt.year\n",
        "\n",
        "    # Cyclic encoding for day, month, hour, minute\n",
        "    df['Day_sin'] = np.sin(2 * np.pi * df['Day'] / 31)\n",
        "    df['Day_cos'] = np.cos(2 * np.pi * df['Day'] / 31)\n",
        "    df['Month_sin'] = np.sin(2 * np.pi * df['Month'] / 12)\n",
        "    df['Month_cos'] = np.cos(2 * np.pi * df['Month'] / 12)\n",
        "    df['Hour_sin'] = np.sin(2 * np.pi * df['Hour'] / 24)\n",
        "    df['Hour_cos'] = np.cos(2 * np.pi * df['Hour'] / 24)\n",
        "    df['Minute_sin'] = np.sin(2 * np.pi * df['Minute'] / 60)\n",
        "    df['Minute_cos'] = np.cos(2 * np.pi * df['Minute'] / 60)\n",
        "    if min_year is None:\n",
        "        min_year = df['Year'].min()\n",
        "\n",
        "    #distance of years   \n",
        "    df['Year_Since'] = df['Year'] - min_year\n",
        "    df.drop(columns=['Timestamp', 'Day', 'Month', 'Hour', 'Minute', 'Year'], inplace=True)\n",
        "    return df, min_year\n",
        "\n",
        "train_df, min_year = transform_dates(train_df)\n",
        "val_df, _ = transform_dates(val_df, min_year)\n",
        "test_df, _ = transform_dates(test_df, min_year)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.1.4 Ad Topic Line"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "I clean the ad text by removing punctuation, stop words, and non-ASCII characters, and converting everything to lowercase"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "def preprocess_ad(text):\n",
        "    text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')    \n",
        "    text = text.replace('--', ' ')    \n",
        "    words = text.split()    \n",
        "    table = str.maketrans('', '', string.punctuation)\n",
        "    words = [w.translate(table) for w in words]    \n",
        "    words = [w.lower() for w in words if w.isalpha() and w.lower() not in stop_words]\n",
        "    return ' '.join(words)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To better understand the input data, I analyze the distribution of the number of words in each ad title after preprocessing. I compute basic statistics and plot a histogram to visualize how ad titles lengths are spread."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for df_ in [train_df, val_df, test_df]:\n",
        "    df_[\"clean_text\"] = df_[\"Ad Topic Line\"].apply(preprocess_ad)\n",
        "    df_[\"ad_length\"] = df_[\"clean_text\"].apply(lambda x: len(x.split()))\n",
        "    df_[\"tokens\"] = df_[\"clean_text\"].str.split()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ad_length_stats = train_df[\"ad_length\"].describe()\n",
        "print(ad_length_stats)\n",
        "print(\"\\n\")\n",
        "quantiles = [0.50, 0.75, 0.90, 0.95, 0.98, 0.99, 1.00]\n",
        "for q in quantiles:\n",
        "    length_at_quantile = train_df[\"ad_length\"].quantile(q)\n",
        "    print(f\"Quantile {q*100:.0f}%: Ads have length <= {length_at_quantile:.0f} words.\")\n",
        "\n",
        "plt.figure(figsize=(14, 7))\n",
        "sns.histplot(data=train_df, x=\"ad_length\", bins=50, kde=True,\n",
        "             label=\"Length distribution\", stat=\"density\")\n",
        "plt.axvline(train_df[\"ad_length\"].quantile(0.75), color='green', linestyle='--',\n",
        "            label=f'75th Quantile ({train_df[\"ad_length\"].quantile(0.75):.0f} words)')\n",
        "plt.axvline(train_df[\"ad_length\"].quantile(0.90), color='orange', linestyle='--',\n",
        "            label=f'90th Quantile ({train_df[\"ad_length\"].quantile(0.90):.0f} words)')\n",
        "plt.axvline(train_df[\"ad_length\"].quantile(0.95), color='red', linestyle='--',\n",
        "            label=f'95th Quantile ({train_df[\"ad_length\"].quantile(0.95):.0f} words)')\n",
        "plt.title('Distribution of Ad Topic Line with Highlighted Quantiles', fontsize=16)\n",
        "plt.xlabel('Number of Words per Ad Topic Line', fontsize=12)\n",
        "plt.ylabel('Density', fontsize=12)\n",
        "plt.legend()\n",
        "plt.xlim(0, train_df[\"ad_length\"].quantile(0.99))\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Based on the text preprocessing, an analysis of the ad topic line lengths was conducted. The distribution and highlighted quantiles reveal several key insights:\n",
        "\n",
        "*   The ad topic lines are predominantly short and concise, with the most frequent length being **3 words**.\n",
        "*   The distribution is highly concentrated, with **75% of ad topic lines having 3 words or fewer**.\n",
        "*   The distribution has a very short tail, as **95% of all ad topic lines contain 4 words or fewer**.\n",
        "\n",
        "Based on this analysis, a maximum sequence length (`MAX_LEN`) of **5** was chosen. This value sits just above the 95th percentile, striking an effective balance: it captures the complete context for the vast majority of samples while minimizing the computational overhead from excessive padding.\n",
        "\n",
        "Consequently, sequences shorter than 5 words will be post-padded to reach this length. To ensure these padding tokens do not influence the model's learning process, the `Embedding` layer will be configured with `mask_zero=True`. This instructs subsequent layers, such as the LSTM, to disregard these padded positions during training, effectively isolating the model's focus on the actual content of the sequence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ad_all_train_words = [word for tokens in train_df['tokens'] for word in tokens]\n",
        "ad_unique_words = sorted(list(set(ad_all_train_words)))\n",
        "\n",
        "ad_word_index = {word: i + 2 for i, word in enumerate(ad_unique_words)}\n",
        "ad_word_index[\"<OOV>\"] = 1\n",
        "AD_MAX_LEN = 5\n",
        "AD_VOCAB_SIZE = len(ad_unique_words) + 2\n",
        "\n",
        "\n",
        "def ad_text_to_sequence(tokens, word_index_dict):\n",
        "    seq = [word_index_dict.get(word, word_index_dict[\"<OOV>\"]) for word in tokens]\n",
        "    return seq\n",
        "\n",
        "ad_train_sequences = [ad_text_to_sequence(tokens, ad_word_index) for tokens in train_df['tokens']]\n",
        "ad_val_sequences = [ad_text_to_sequence(tokens, ad_word_index) for tokens in val_df['tokens']]\n",
        "ad_test_sequences = [ad_text_to_sequence(tokens, ad_word_index) for tokens in test_df['tokens']]\n",
        "\n",
        "train_ad_seqs = pad_sequences(ad_train_sequences, maxlen=AD_MAX_LEN, padding='post', truncating='post')\n",
        "val_ad_seqs = pad_sequences(ad_val_sequences, maxlen=AD_MAX_LEN, padding='post', truncating='post')\n",
        "test_ad_seqs = pad_sequences(ad_test_sequences, maxlen=AD_MAX_LEN, padding='post', truncating='post')\n",
        "\n",
        "print(\"Shape of final training sequences tensor:\", train_ad_seqs.shape)\n",
        "print(\"Example of a processed sequence:\", train_ad_seqs[29])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.1.5 Country"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def preprocess_location(country):\n",
        "    # Normalize unicode\n",
        "    country = unicodedata.normalize('NFKD', country).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
        "    country = country.replace('--', ' ')\n",
        "    # Remove punctuation except spaces\n",
        "    table = str.maketrans('', '', string.punctuation.replace(' ', ''))\n",
        "    country = country.translate(table)\n",
        "    country = country.lower()\n",
        "    # Remove extra spaces\n",
        "    country = ' '.join(country.split())\n",
        "    # Join multi-word country names with no separator (single word)\n",
        "    country = country.replace(' ', '')\n",
        "    # Only allow alphabetic (no numbers or other chars)\n",
        "    if country.isalpha() and country:\n",
        "        return country\n",
        "    else:\n",
        "        return ''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for df_ in [train_df, val_df, test_df]:\n",
        "    df_[\"clean_country\"] = df_[\"Country\"].apply(preprocess_location)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_word_index(words):\n",
        "    \"\"\"\n",
        "    Create a word-to-index dictionary for a list of words.\n",
        "    Indexing starts at 2, with 1 reserved for <OOV>.\n",
        "    \"\"\"\n",
        "    unique_words = sorted(set(words))\n",
        "    word_index = {word: i + 2 for i, word in enumerate(unique_words)}\n",
        "    word_index[\"<OOV>\"] = 1\n",
        "    return word_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Create word index for clean_country using only train_df to avoid data leakage\n",
        "country_word_index = create_word_index(train_df[\"clean_country\"])\n",
        "COUNTRY_VOCAB_SIZE = len(country_word_index) + 1\n",
        "\n",
        "def country_to_index(country):\n",
        "    return country_word_index.get(country, country_word_index[\"<OOV>\"])\n",
        "\n",
        "train_country_tensor = train_df[\"clean_country\"].apply(country_to_index).values\n",
        "val_country_tensor = val_df[\"clean_country\"].apply(country_to_index).values\n",
        "test_country_tensor = test_df[\"clean_country\"].apply(country_to_index).values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.1.6 city"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for df_ in [train_df, val_df, test_df]:\n",
        "    df_[\"clean_city\"] = df_[\"City\"].apply(preprocess_location)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create word index for clean_city using only train_df to avoid data leakage\n",
        "city_word_index = create_word_index(train_df[\"clean_city\"])\n",
        "CITY_VOCAB_SIZE = len(city_word_index) + 1 \n",
        "\n",
        "def city_to_index(city):\n",
        "    return city_word_index.get(city, city_word_index[\"<OOV>\"])\n",
        "\n",
        "train_city_tensor = train_df[\"clean_city\"].apply(city_to_index).values\n",
        "val_city_tensor = val_df[\"clean_city\"].apply(city_to_index).values\n",
        "test_city_tensor = test_df[\"clean_city\"].apply(city_to_index).values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.1.7 - Numerical group of features: Age,  Area Income,  Daily Internet Usage, Male, Daily Time Spent on Site, converted timestamp "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "numeric_cols = [\n",
        "    'Age', 'Area Income', 'Daily Internet Usage', 'Male', 'Daily Time Spent on Site',\n",
        "    'Day_sin', 'Day_cos', 'Month_sin', 'Month_cos',\n",
        "    'Hour_sin', 'Hour_cos', 'Minute_sin', 'Minute_cos', 'Year_Since'\n",
        "]\n",
        "\n",
        "train_nums_tensor = scaler.fit_transform(train_df[numeric_cols])\n",
        "val_nums_tensor   = scaler.transform(val_df[numeric_cols])\n",
        "test_nums_tensor  = scaler.transform(test_df[numeric_cols])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tjICOJlGQAIz"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2.2. Input of the model "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The model architecture is designed to accept five distinct and parallel inputs, each representing a different type of information extracted from the original data. This multi-input architecture allows the model to learn specific representations for each data type before merging them for the final prediction.\n",
        "\n",
        "The five input tensors are summarized below, showing the shape and a brief description of their content. These tensors represent the textual, categorical, and numerical data, respectively.\n",
        "\n",
        "As outlined in the exam, the textual data input will be processed either by an embedding layer or an LSTM layer. The other two inputs (categorical and numerical), which are here separated just for clarity, will be concatenated with the output representation from the embeddign layers and the lstm layer. This combined vector will then serve as the input for the subsequent fully-connected deep neural network."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "print(\"\\n1. TEXTUAL INPUT -Ad Topic Line (Padded Token Sequences)\")\n",
        "print(f\"   - Training tensor shape: {train_ad_seqs.shape}\")\n",
        "print(f\"   - Validation tensor shape: {val_ad_seqs.shape}\")\n",
        "print(f\"   - Test tensor shape: {test_ad_seqs.shape}\")\n",
        "\n",
        "print(\"\\n2. TEXTUAL INPUT -Country (integer index)\")\n",
        "print(f\"   - Training tensor shape: {train_country_tensor.shape}\")\n",
        "print(f\"   - Validation tensor shape: {val_country_tensor.shape}\")\n",
        "print(f\"   - Test tensor shape: {test_country_tensor.shape}\")\n",
        "\n",
        "print(\"\\n3. TEXTUAL INPUT -City (integer index)\")\n",
        "print(f\"   - Training tensor shape: {train_city_tensor.shape}\")\n",
        "print(f\"   - Validation tensor shape: {val_city_tensor.shape}\")\n",
        "print(f\"   - Test tensor shape: {test_city_tensor.shape}\")\n",
        "\n",
        "print(\"\\n4. CATEGORICAL INPUT (One-Hot Encoded)\")\n",
        "print(f\"   - Training tensor shape: {train_hot_tensor.shape}\")\n",
        "print(f\"   - Validation tensor shape: {val_hot_tensor.shape}\")\n",
        "print(f\"   - Test tensor shape: {test_hot_tensor.shape}\")\n",
        "\n",
        "print(\"\\n5. NUMERICAL INPUT (Normalized Features)\")\n",
        "print(f\"   - Training tensor shape: {train_nums_tensor.shape}\")\n",
        "print(f\"   - Validation tensor shape: {val_nums_tensor.shape}\")\n",
        "print(f\"   - Test tensor shape: {test_nums_tensor.shape}\")\n",
        "print(f\"   - Included columns: {numeric_cols}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-2yUKMrkaWn1"
      },
      "source": [
        "# 3 - 4 (OUTPUT - LOSS - MODEL CONFIGURATION)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IOw9bozw7a-L"
      },
      "source": [
        "This section represents the following three parts:\n",
        "\n",
        "3. OUTPUT/LOSS: How would you design the output layer and why; Which loss function would you use to train your model and\n",
        "why;\n",
        "4. MODEL CONFIGURATION\n",
        "  * Model overall composition/pipeline,\n",
        "  * model optimization;"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3.1 Output Layer, Loss Function, and Label Preprocessing\n",
        "\n",
        "- **Label Preprocessing**: The target labels (`Clicked on Ad`) are already encoded as integers (0 and 1). I will keep them in this integer format rather than manually one-hot encoding them. This is because I will be using the `sparse_categorical_crossentropy` loss function, which is designed to work directly with integer labels. It's important to note that, under the hood, this is equivalent to comparing the model's output probabilities with a one-hot encoded ground truth.\n",
        "\n",
        "- **Output Layer**: As explained during the exam, the model's final layer will be a `Dense` layer with **two units and a softmax activation function**. A two-unit softmax output is crucial because frameworks like LIME require the model to output a full probability distribution over all classes (in this case, `P(Did Not Click)` and `P(Clicked)`) for its analysis. A single sigmoid unit would only provide the probability for the positive class.\n",
        "\n",
        "- **Loss Function**: Given that the model outputs a probability distribution, the ideal loss function is `sparse_categorical_crossentropy`. Its purpose is to minimize the divergence (specifically, the cross-entropy) between the model's predicted probability distribution and the true distribution (represented by the integer labels). This effectively trains the model to produce predictions that accurately match the ground truth probabilities."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_labels = train_df[\"Clicked on Ad\"]\n",
        "val_labels = val_df[\"Clicked on Ad\"]\n",
        "test_labels = test_df[\"Clicked on Ad\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3.2  MODEL CONFIGURATION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ILhjDBpq5k5S"
      },
      "outputs": [],
      "source": [
        "\n",
        "def create_model(\n",
        "    country_vocab_size,\n",
        "    city_vocab_size,\n",
        "    ad_vocab_size,\n",
        "    query_onehot_dim,\n",
        "    numeric_features,\n",
        "    ad_max_len=5,\n",
        "    country_max_len=1,\n",
        "    city_max_len=1,\n",
        "    ad_embedding_dim=32,\n",
        "    ad_lstm_units=16,\n",
        "    country_embedding_dim=8,\n",
        "    city_embedding_dim=8,\n",
        "    hidden_layer_sizes=[256, 128, 64, 32],\n",
        "    dropout_rate=0.1,\n",
        "    weight_reg=l2(0.01)\n",
        "):\n",
        "    country_input = Input(shape=(country_max_len,), name='country_input')\n",
        "    city_input = Input(shape=(city_max_len,), name='city_input')\n",
        "    ad_input = Input(shape=(ad_max_len,), name='ad_input')\n",
        "    query_input = Input(shape=(query_onehot_dim,), name='query_input')\n",
        "    numeric_input = Input(shape=(numeric_features,), name='numeric_input')\n",
        "\n",
        "\n",
        "    x_country_text = Embedding(input_dim=country_vocab_size,\n",
        "                       output_dim=country_embedding_dim,\n",
        "                       input_length=country_max_len)(country_input)\n",
        "    x_country_text = Flatten()(x_country_text)\n",
        "\n",
        "\n",
        "    \n",
        "    x_city_text = Embedding(input_dim=city_vocab_size,\n",
        "                       output_dim=city_embedding_dim,\n",
        "                       input_length=city_max_len)(city_input)\n",
        "    x_city_text = Flatten()(x_city_text)\n",
        "\n",
        "\n",
        "    x_ad_text = Embedding(input_dim=ad_vocab_size,\n",
        "                       output_dim=ad_embedding_dim,\n",
        "                       input_length=ad_max_len,\n",
        "                       mask_zero=True)(ad_input)\n",
        "    x_ad_text = LSTM(ad_lstm_units,\n",
        "                                activation='tanh',\n",
        "                                recurrent_activation='sigmoid',\n",
        "                                dropout=dropout_rate,\n",
        "                                recurrent_dropout=dropout_rate,\n",
        "                                kernel_initializer='glorot_uniform', \n",
        "                                recurrent_initializer='glorot_uniform'\n",
        "                               )(x_ad_text)\n",
        "\n",
        "    x = Concatenate()([x_ad_text, x_country_text, x_city_text, query_input, numeric_input])\n",
        "\n",
        "\n",
        "    for i, size in enumerate(hidden_layer_sizes, start=1):\n",
        "        x = Dense(size,\n",
        "                  activation='relu',\n",
        "                  kernel_initializer='he_uniform',\n",
        "                  kernel_regularizer=weight_reg,\n",
        "                  name=f'dense_{i}')(x)\n",
        "        x = BatchNormalization(name=f'bn_{i}')(x)\n",
        "        x = Dropout(dropout_rate, name=f'dropout_{i}')(x)\n",
        "\n",
        "    output = Dense(2, activation=\"softmax\")(x)\n",
        "\n",
        "    return Model(inputs=[country_input, city_input, ad_input, query_input, numeric_input],\n",
        "                 outputs=[output])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5 - Hyperparametr optimization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "param_grid = {\n",
        "    'learning_rate':     [2e-3, 5e-3, 1e-2],\n",
        "    'batch_size':        [64, 128, 256],\n",
        "    'epochs':            [5, 10, 20, 25],\n",
        "    'dropout_rate':      [0.2, 0.3, 0.4, 0.5],\n",
        "    'weight_reg':        [l2(1e-4), l2(1e-3), l2(1e-2)],\n",
        "    'ad_embedding_dim':  [16, 32, 64],\n",
        "    'ad_lstm_units':     [8, 16, 32],\n",
        "    'country_embedding_dim': [4, 8, 16],\n",
        "    'city_embedding_dim':    [4, 8, 16],\n",
        "    'optimizer':         ['adam'],\n",
        "    'hidden_layer_sizes': [\n",
        "        [256, 128, 64, 32],\n",
        "        [128, 64, 32],\n",
        "        [64, 32]\n",
        "    ]\n",
        "}\n",
        "num_samples = 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- We are tuning parameters like learning_rate, dropout_rate, and loss_weight_score, which have a significant influence on model convergence and generalization without drastically increasing training time per trial. More computationally expensive parameters, such as the number of LSTM layers or a much wider range for embedding_dim, have been intentionally kept fixed or limited. This focused approach allows for an efficient yet meaningful optimization process within the available computational budget.\n",
        "\n",
        "- Due to time constraints, the following random search is limited to num_samples = 5. This serves as a proof of concept for the tuning methodology rather than an exhaustive search for an optimal model. For the final evaluation, a pre-vetted, well performing configuration is used to ensure a meaningful analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def random_search(param_grid, samples=5):\n",
        "    \"\"\"\n",
        "    Performs a random hyperparameter search for the classification model.\n",
        "    \"\"\"\n",
        "    combos = list(itertools.product(*param_grid.values()))\n",
        "    num_to_sample = min(samples, len(combos))\n",
        "    sampled_combos = random.sample(combos, num_to_sample)\n",
        "    configs = [dict(zip(param_grid.keys(), c)) for c in sampled_combos]\n",
        "\n",
        "    best_model = {\n",
        "        'f1_score': (0, None),\n",
        "        'accuracy': (0, None)\n",
        "    }\n",
        "\n",
        "    # Prepare input dictionaries using the provided variable names\n",
        "    train_inputs = {\n",
        "        'country_input': train_country_tensor,\n",
        "        'city_input': train_city_tensor,\n",
        "        'ad_input': train_ad_seqs,\n",
        "        'query_input': train_hot_tensor,\n",
        "        'numeric_input': train_nums_tensor\n",
        "    }\n",
        "    val_inputs = {\n",
        "        'country_input': val_country_tensor,\n",
        "        'city_input': val_city_tensor,\n",
        "        'ad_input': val_ad_seqs,\n",
        "        'query_input': val_hot_tensor,\n",
        "        'numeric_input': val_nums_tensor\n",
        "    }\n",
        "\n",
        "    for idx, cfg in enumerate(configs):\n",
        "        K.clear_session()\n",
        "        print(f\"\\n{'='*10} Training config {idx+1}/{len(configs)} {'='*10}\")\n",
        "        print(\"Config:\", cfg)\n",
        "        \n",
        "        # 1. Model Creation\n",
        "        # The dimensions are obtained dynamically from the shapes of the input tensors\n",
        "        model = create_model(\n",
        "            country_vocab_size=COUNTRY_VOCAB_SIZE,\n",
        "            city_vocab_size=CITY_VOCAB_SIZE,\n",
        "            ad_vocab_size=AD_VOCAB_SIZE,\n",
        "            query_onehot_dim=train_hot_tensor.shape[1],\n",
        "            numeric_features=train_nums_tensor.shape[1],\n",
        "            ad_max_len=train_ad_seqs.shape[1],\n",
        "            country_max_len=1, #train_country_tensor.shape[1],\n",
        "            city_max_len=1, #train_city_tensor.shape[1],\n",
        "            ad_embedding_dim=cfg['ad_embedding_dim'],\n",
        "            ad_lstm_units=cfg['ad_lstm_units'],\n",
        "            country_embedding_dim=cfg['country_embedding_dim'],\n",
        "            city_embedding_dim=cfg['city_embedding_dim'],\n",
        "            hidden_layer_sizes=cfg['hidden_layer_sizes'],\n",
        "            dropout_rate=cfg['dropout_rate'],\n",
        "            weight_reg=cfg['weight_reg']\n",
        "        )\n",
        "\n",
        "        Optimizer = keras.optimizers.Adam if cfg['optimizer'] == 'adam' else keras.optimizers.RMSprop\n",
        "        model.compile(\n",
        "            loss='sparse_categorical_crossentropy',\n",
        "            optimizer=Optimizer(learning_rate=cfg['learning_rate']),\n",
        "            metrics=['accuracy']\n",
        "        )\n",
        "\n",
        "        # 3. Model Training\n",
        "        history = model.fit(\n",
        "            train_inputs,\n",
        "            train_labels,\n",
        "            epochs=cfg['epochs'],\n",
        "            batch_size=cfg['batch_size'],\n",
        "            validation_data=(val_inputs, val_labels), \n",
        "            verbose=1,\n",
        "            callbacks=[\n",
        "                keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "            ]\n",
        "        )\n",
        "        \n",
        "        # 4. Evaluation\n",
        "        pred_probs = model.predict(val_inputs, verbose=0)\n",
        "        pred_labels = np.argmax(pred_probs, axis=1) \n",
        "\n",
        "        true_labels = val_labels\n",
        "        acc = accuracy_score(true_labels, pred_labels)\n",
        "        f1 = f1_score(true_labels, pred_labels, average='weighted')\n",
        "        \n",
        "        print(\"\\nEvaluation metrics:\")\n",
        "        print(f\"  Accuracy = {acc:.4f}, F1-Score = {f1:.4f}\\n\")\n",
        "        # zero_division=0 to avoid warnings if a class has no predictions\n",
        "        print(classification_report(true_labels, pred_labels, zero_division=0))\n",
        "        # 5. Update best results\n",
        "        if f1 > best_model['f1_score'][0]:\n",
        "            best_model['f1_score'] = (f1, cfg)\n",
        "        if acc > best_model['accuracy'][0]:\n",
        "            best_model['accuracy'] = (acc, cfg)\n",
        "\n",
        "    print(\"\\n{'='*15} Best Results Summary {'='*15}\")\n",
        "    print(f\"Best model (by F1-Score): {best_model['f1_score'][0]:.4f} -> Config: {best_model['f1_score'][1]}\")\n",
        "    print(f\"Best model (by Accuracy): {best_model['accuracy'][0]:.4f} -> Config: {best_model['accuracy'][1]}\")\n",
        "    \n",
        "    return best_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_results = random_search(param_grid)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The following configuration was identified as a well performing candidate during more extensive, offline experiments. For reproducibility within this notebook, we will use this specific configuration for final training and evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V3Xv4zQbTTYA"
      },
      "outputs": [],
      "source": [
        "best_learning_rate = 0.005\n",
        "best_batch_size = 64\n",
        "best_epochs = 20\n",
        "best_dropout_rate = 0.4\n",
        "best_weight_reg = keras.regularizers.l2(1e-2)\n",
        "best_ad_embedding_dim = 16\n",
        "best_ad_lstm_units = 16\n",
        "best_country_embedding_dim = 16\n",
        "best_city_embedding_dim = 4\n",
        "best_optimizer = 'adam'\n",
        "best_hidden_layer_sizes = [256, 128, 64, 32]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "KL2fLtnT_9mC",
        "outputId": "42a51041-cacb-4cf9-e424-3b3f067bc2f5"
      },
      "outputs": [],
      "source": [
        "# Set initial random state for reproducibility\n",
        "RANDOM_SEED = 42\n",
        "random.seed(RANDOM_SEED)\n",
        "np.random.seed(RANDOM_SEED)\n",
        "tf.random.set_seed(RANDOM_SEED)\n",
        "\n",
        "K.clear_session()\n",
        "\n",
        "best_model = create_model(\n",
        "    country_vocab_size=COUNTRY_VOCAB_SIZE,\n",
        "    city_vocab_size=CITY_VOCAB_SIZE,\n",
        "    ad_vocab_size=AD_VOCAB_SIZE,\n",
        "    query_onehot_dim=train_hot_tensor.shape[1],\n",
        "    numeric_features=train_nums_tensor.shape[1],\n",
        "    ad_max_len=train_ad_seqs.shape[1],\n",
        "    country_max_len=1,  # train_country_tensor.shape[1],\n",
        "    city_max_len=1,     # train_city_tensor.shape[1],\n",
        "    ad_embedding_dim=best_ad_embedding_dim,\n",
        "    ad_lstm_units=best_ad_lstm_units,\n",
        "    country_embedding_dim=best_country_embedding_dim,\n",
        "    city_embedding_dim=best_city_embedding_dim,\n",
        "    hidden_layer_sizes=best_hidden_layer_sizes,\n",
        "    dropout_rate=best_dropout_rate,\n",
        "    weight_reg=best_weight_reg\n",
        ")\n",
        "\n",
        "Optimizer = keras.optimizers.Adam if best_optimizer == 'adam' else keras.optimizers.RMSprop\n",
        "\n",
        "best_model.compile(\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    optimizer=Optimizer(learning_rate=best_learning_rate),\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "train_inputs = {\n",
        "    'country_input': train_country_tensor,\n",
        "    'city_input': train_city_tensor,\n",
        "    'ad_input': train_ad_seqs,\n",
        "    'query_input': train_hot_tensor,\n",
        "    'numeric_input': train_nums_tensor\n",
        "}\n",
        "val_inputs = {\n",
        "    'country_input': val_country_tensor,\n",
        "    'city_input': val_city_tensor,\n",
        "    'ad_input': val_ad_seqs,\n",
        "    'query_input': val_hot_tensor,\n",
        "    'numeric_input': val_nums_tensor\n",
        "}\n",
        "\n",
        "history = best_model.fit(\n",
        "            train_inputs,\n",
        "            train_labels, \n",
        "            epochs=best_epochs,\n",
        "            batch_size=best_batch_size,\n",
        "            validation_data=(val_inputs, val_labels),\n",
        "            verbose=1,\n",
        "            callbacks=[keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "import os \n",
        "print(\"=\"*60)\n",
        "print(\"MODEL COMPOSITION REPORT\")\n",
        "print(\"=\"*60)\n",
        "best_model.summary()\n",
        "\n",
        "\n",
        "print(\"\\n\\n\" + \"=\"*60)\n",
        "print(\"MODEL ARCHITECTURE PLOT\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "\n",
        "plot_model(\n",
        "best_model,\n",
        "to_file='model_architecture.png',\n",
        "show_shapes=True,           \n",
        "show_layer_names=True,      \n",
        "show_dtype=False,           \n",
        "show_layer_activations=True )\n",
        "\n",
        "\n",
        "if os.path.exists(\"model_architecture.png\"):\n",
        "    display(Image('model_architecture.png'))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The plots below illustrate the training and validation performance of the classification model over successive epochs. We analyze the learning curves for both the loss function and key performance metrics, primarily accuracy. This analysis is essential for evaluating model convergence, identifying signs of overfitting by observing the divergence between training and validation scores, and ultimately assessing the efficacy of the chosen training configuration."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_training_history(history):\n",
        "    train_loss = history.history.get('loss', [])\n",
        "    val_loss = history.history.get('val_loss', [])\n",
        "    train_acc = history.history.get('accuracy', [])\n",
        "    val_acc = history.history.get('val_accuracy', [])\n",
        "\n",
        "    epochs = range(1, len(train_loss) + 1)\n",
        "\n",
        "    fig, axs = plt.subplots(1, 2, figsize=(14, 6))\n",
        "    fig.suptitle('Training and Validation History', fontsize=20)\n",
        "\n",
        "    axs[0].plot(epochs, train_loss, 'bo-', label='Training Loss')\n",
        "    axs[0].plot(epochs, val_loss, 'ro-', label='Validation Loss')\n",
        "    axs[0].set_title('Loss')\n",
        "    axs[0].set_xlabel('Epochs')\n",
        "    axs[0].set_ylabel('Loss')\n",
        "    axs[0].legend()\n",
        "    axs[0].grid(True)\n",
        "\n",
        "    if train_acc and val_acc:\n",
        "        axs[1].plot(epochs, train_acc, 'bo-', label='Training Accuracy')\n",
        "        axs[1].plot(epochs, val_acc, 'ro-', label='Validation Accuracy')\n",
        "        axs[1].set_title('Accuracy')\n",
        "        axs[1].set_xlabel('Epochs')\n",
        "        axs[1].set_ylabel('Accuracy')\n",
        "        axs[1].legend()\n",
        "        axs[1].grid(True)\n",
        "    else:\n",
        "        axs[1].set_visible(False)\n",
        "\n",
        "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
        "    plt.show()\n",
        "\n",
        "plot_training_history(history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 5 - MODEL EVALUATION"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This section is dedicated to the final evaluation of the best-performing model, identified through the hyperparameter optimization process.\n",
        "\n",
        "The evaluation is conducted on the **unseen test set** to provide an unbiased estimate of the model's generalization capabilities. The process follows the plan outlined in the exam:\n",
        "1.  Evaluate the classification task.\n",
        "2.  Visualize the results to gain deeper insights (e.g., Confusion Matrix and performance plots)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, classification_report\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Predict on test set\n",
        "test_pred_probs = best_model.predict(\n",
        "    {\n",
        "        'country_input': test_country_tensor,\n",
        "        'city_input': test_city_tensor,\n",
        "        'ad_input': test_ad_seqs,\n",
        "        'query_input': test_hot_tensor,\n",
        "        'numeric_input': test_nums_tensor\n",
        "    },\n",
        "    verbose=0\n",
        ")\n",
        "test_pred_labels = np.argmax(test_pred_probs, axis=1)\n",
        "y_true = test_labels\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_true, test_pred_labels)\n",
        "# Plot Confusion Matrix\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# Classification Report\n",
        "report = classification_report(y_true, test_pred_labels)\n",
        "print(\"Classification Report:\\n\", report)\n",
        "\n",
        "\n",
        "# Accuracy Score\n",
        "acc = accuracy_score(y_true, test_pred_labels)\n",
        "print(\"Accuracy Score:\", acc)\n",
        "\n",
        "# F1 Score\n",
        "f1 = f1_score(y_true, test_pred_labels, average='weighted')\n",
        "print(\"F1 Score (weighted):\", f1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 6 - MODEL INTERPRETATION (LIME )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "As outlined during the exam, we will use the LIME framework to generate local explanations for the model's predictions. However, our model's multi-modal architecture, which accepts both tabular and textual inputs, presents a technical challenge. LIME is structured with distinct explainers for different data types, namely `LimeTabularExplainer`, `LimeTextExplainer`, and `LimeImageExplainer`.\n",
        "\n",
        " **Method 1: Explanation with a Subset of Features**\n",
        "> Following the idea discussed in the exam—*\"We can decide to use all the features or some of them to train the linear model\"*—our first approach will be to generate an explanation using only the non-textual features. This allows us to use the standard `LimeTabularExplainer` on the numerical data only. The primary limitation of this approach is significant: it cannot account for the impact of textual features, thus providing an incomplete view of the model's reasoning. We will implement this method first to demonstrate its functionality and its inherent drawbacks.\n",
        "\n",
        "**Method 2: A Holistic Explanation with all the features**\n",
        "> To overcome the limitations of the first method and obtain a complete explanation, a more sophisticated strategy is required. This approach involves treating the entire multi-input data as a single, unified tabular array for LIME. The key to this method is a custom 'wrapper' function that serves as an intermediary. This wrapper receives the perturbed data from LIME, correctly reshapes it into the multiple distinct inputs our Keras model expects, and returns the prediction. This allows us to leverage the power of `LimeTabularExplainer` across all features simultaneously, ensuring a complete and faithful interpretation of our black-box model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6.1 Explanation with a Subset of Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import lime\n",
        "import lime.lime_tabular\n",
        "import numpy as np\n",
        "from IPython.display import display, HTML, Markdown"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 6.1.1- extract the numerical features only \n",
        "X_train_for_lime_explainer = train_nums_tensor\n",
        "feature_names_for_lime_explainer = numeric_cols\n",
        "print(f\"Shape of the data provided to the LIME explainer: {X_train_for_lime_explainer.shape}\")\n",
        "print(f\"Number of feature names provided: {len(feature_names_for_lime_explainer)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# This wrapper is the bridge between LIME's simplified world (only numerics) and our complex model's world (all 5 inputs)\n",
        "def prediction_wrapper_numerics_only(perturbed_numerical_data):\n",
        "    num_samples = perturbed_numerical_data.shape[0]\n",
        "    # Create fixed, neutral placeholders for all inputs that LIME is NOT perturbing.\n",
        "    placeholder_country = np.zeros((num_samples, 1), dtype=int)\n",
        "    placeholder_city = np.zeros((num_samples, 1), dtype=int)\n",
        "    placeholder_ad = np.zeros((num_samples, AD_MAX_LEN), dtype=int)\n",
        "    placeholder_query = np.zeros((num_samples, train_hot_tensor.shape[1]), dtype=int)\n",
        "    # Assemble the full input for the original `best_model`.\n",
        "    model_inputs = {\n",
        "        'country_input': placeholder_country,\n",
        "        'city_input': placeholder_city,\n",
        "        'ad_input': placeholder_ad,\n",
        "        'query_input': placeholder_query,\n",
        "        'numeric_input': perturbed_numerical_data  # only part that varies.\n",
        "    }\n",
        "    # Get a prediction from the original, fully-trained black-box model.\n",
        "    return best_model.predict(model_inputs, verbose=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "explainer_numerics_only = lime.lime_tabular.LimeTabularExplainer(\n",
        "    training_data=X_train_for_lime_explainer,\n",
        "    feature_names=feature_names_for_lime_explainer,\n",
        "    class_names=['Did Not Click', 'Clicked'],\n",
        "    mode='classification',\n",
        "    random_state=42\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "instance_idx = 33 # instance from the test set to explain.\n",
        "\n",
        "instance_to_explain_numerics_only = test_nums_tensor[instance_idx]\n",
        "# Get the model's prediction for this instance's numerics\n",
        "prediction_probs_numerics = prediction_wrapper_numerics_only(instance_to_explain_numerics_only.reshape(1, -1))\n",
        "predicted_label_numerics = np.argmax(prediction_probs_numerics)\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(f\"NUMERICS-ONLY EXPLANATION FOR INSTANCE #{instance_idx}\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Original True Label: {'Clicked' if test_labels.iloc[instance_idx] == 1 else 'Did Not Click'}\")\n",
        "print(f\"Model Prediction (based on its numerical inputs only): {'Clicked' if predicted_label_numerics == 1 else 'Did Not Click'}\")\n",
        "print(f\"Prediction Probabilities: {prediction_probs_numerics[0]}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "explanation_numerics_only = explainer_numerics_only.explain_instance(\n",
        "    instance_to_explain_numerics_only,\n",
        "    prediction_wrapper_numerics_only,\n",
        "    num_features=10,\n",
        "    top_labels=1\n",
        ")\n",
        "html_explanation_numerics = explanation_numerics_only.as_html(show_table=True, show_all=False)\n",
        "display(HTML(html_explanation_numerics))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6.2 Explanation with all the features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# 1. Convert one-hot encoded queries to a single categorical index.\n",
        "train_query_indices = np.argmax(train_hot_tensor, axis=1)\n",
        "test_query_indices = np.argmax(test_hot_tensor, axis=1) # We'll need this for the instance to explain\n",
        "NUM_QUERY_CATEGORIES = train_hot_tensor.shape[1]\n",
        "\n",
        "# 2. Create inverse mapping dictionaries (index -> word/name).\n",
        "def invert_word_index(word_index):\n",
        "    return {idx: word for word, idx in word_index.items()}\n",
        "\n",
        "index_to_country = invert_word_index(country_word_index)\n",
        "index_to_city = invert_word_index(city_word_index)\n",
        "index_to_ad_word = invert_word_index(ad_word_index)\n",
        "index_to_query_name = {i: f\"Query_{i}\" for i in range(NUM_QUERY_CATEGORIES)}\n",
        "\n",
        "# 3. Add mappings for padding/OOV tokens.\n",
        "index_to_country[0] = '<N/A>'\n",
        "index_to_city[0] = '<N/A>'\n",
        "index_to_ad_word[0] = '<PAD>'\n",
        "\n",
        "# 4. Assemble the unified training data matrix for LIME.\n",
        "train_country_tensor_2d = train_country_tensor.reshape(-1, 1)\n",
        "train_city_tensor_2d = train_city_tensor.reshape(-1, 1)\n",
        "train_query_indices_2d = train_query_indices.reshape(-1, 1)\n",
        "\n",
        "X_train_unified = np.hstack([\n",
        "    train_country_tensor_2d,\n",
        "    train_city_tensor_2d,\n",
        "    train_ad_seqs,\n",
        "    train_query_indices_2d,\n",
        "    train_nums_tensor\n",
        "])\n",
        "\n",
        "print(f\"Shape of the unified training matrix for LIME: {X_train_unified.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1. Define the complete list of feature names in the correct order.\n",
        "country_feature_names = ['Country']\n",
        "city_feature_names = ['City']\n",
        "ad_feature_names = [f'Ad_Word_{i+1}' for i in range(AD_MAX_LEN)]\n",
        "query_feature_names = ['Search_Query']\n",
        "feature_names = (\n",
        "    country_feature_names + city_feature_names + ad_feature_names +\n",
        "    query_feature_names + numeric_cols\n",
        ")\n",
        "\n",
        "# 2. Identify the indices of all categorical features.\n",
        "num_categorical_features = (\n",
        "    len(country_feature_names) + len(city_feature_names) +\n",
        "    len(ad_feature_names) + len(query_feature_names)\n",
        ")\n",
        "categorical_features_indices = list(range(num_categorical_features))\n",
        "\n",
        "# 3. Build the dictionary that maps feature indices to their translation maps.\n",
        "categorical_names = {}\n",
        "categorical_names[feature_names.index('Country')] = index_to_country\n",
        "categorical_names[feature_names.index('City')] = index_to_city\n",
        "for i in range(AD_MAX_LEN):\n",
        "    categorical_names[feature_names.index(f'Ad_Word_{i+1}')] = index_to_ad_word\n",
        "categorical_names[feature_names.index('Search_Query')] = index_to_query_name"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "*Handling One-Hot Encoded Features for LIME*\n",
        "\n",
        "The one-hot encoding of the `Search Query` feature required a specific handling strategy to ensure meaningful explanations. `LimeTabularExplainer` interprets each column of a one-hot vector as an independent binary feature, which violates the mutually exclusive nature of the original categorical data and leads to nonsensical perturbations,also, leaving the `Search Query` as it is, would bring to and output that is low-level and confusing, such as \"`Query_164=0` contributed positively,\" which fails to capture the high-level concept of the user's search. If anyone is interested I left this version as the final point **6.3 - appendix**, to demonstrate how all the categorical features take over the explanations of LIME, making it practically useless\n",
        "\n",
        "\n",
        "To address this, we implemented a conversion process. For the explainer, the one-hot vectors were collapsed into a single categorical feature representing the query's index. This forces LIME to perturb the entire feature at a conceptual level (i.e., changing the query). Subsequently, the `prediction_wrapper` function is responsible for re-expanding this index back into the one-hot format required by the Keras model's `query_input` layer. This round-trip conversion ensures both a conceptually sound explanation from LIME and valid communication with the trained black-box model.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# This wrapper function translates LIME's unified tabular data into the\n",
        "# multi-input format required by our trained Keras model.\n",
        "def prediction_wrapper(data):\n",
        "    # Define slicing points based on the unified data structure\n",
        "    country_end = 1\n",
        "    city_end = country_end + 1\n",
        "    ad_end = city_end + AD_MAX_LEN\n",
        "    query_end = ad_end + 1\n",
        "    \n",
        "    # Slice the data into its constituent parts\n",
        "    country_input = data[:, :country_end].astype(int)\n",
        "    city_input = data[:, country_end:city_end].astype(int)\n",
        "    ad_input = data[:, city_end:ad_end].astype(int)\n",
        "    query_indices = data[:, ad_end:query_end].astype(int)\n",
        "    numeric_input = data[:, query_end:]\n",
        "    \n",
        "    # Revert the query index back to one-hot format for the model\n",
        "    query_input_onehot = to_categorical(query_indices, num_classes=NUM_QUERY_CATEGORIES)\n",
        "    \n",
        "    # Assemble the input dictionary for the model\n",
        "    model_inputs = {\n",
        "        'country_input': country_input,\n",
        "        'city_input': city_input,\n",
        "        'ad_input': ad_input,\n",
        "        'query_input': query_input_onehot,\n",
        "        'numeric_input': numeric_input\n",
        "    }\n",
        "    \n",
        "    # Return the model's prediction\n",
        "    return best_model.predict(model_inputs, verbose=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create the holistic LIME explainer with our custom settings.\n",
        "explainer = lime.lime_tabular.LimeTabularExplainer(\n",
        "    training_data=X_train_unified,\n",
        "    feature_names=feature_names,\n",
        "    class_names=['Did Not Click', 'Clicked'],\n",
        "    categorical_features=categorical_features_indices,\n",
        "    categorical_names=categorical_names,\n",
        "    mode='classification',\n",
        "    random_state=42\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Select a specific instance from the test set to explain.\n",
        "instance_idx = 33\n",
        "original_instance_data = test_df.iloc[instance_idx]\n",
        "\n",
        "# Assemble the unified data vector for this specific instance.\n",
        "instance_to_explain = np.hstack([\n",
        "    test_country_tensor[instance_idx].reshape(1, -1),\n",
        "    test_city_tensor[instance_idx].reshape(1, -1),\n",
        "    test_ad_seqs[instance_idx].reshape(1, -1),\n",
        "    test_query_indices[instance_idx].reshape(1, -1),\n",
        "    test_nums_tensor[instance_idx].reshape(1, -1)\n",
        "]).flatten()\n",
        "\n",
        "# Get the true label and the model's prediction for this instance.\n",
        "true_label = test_labels.iloc[instance_idx]\n",
        "prediction_probs = prediction_wrapper(instance_to_explain.reshape(1, -1))\n",
        "predicted_label = np.argmax(prediction_probs)\n",
        "\n",
        "# Print a summary header.\n",
        "print(\"=\"*60)\n",
        "print(f\"DETAILED EXPLANATION FOR INSTANCE #{instance_idx} FROM THE TEST SET\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Original Ad Topic Line: '{original_instance_data['Ad Topic Line']}'\")\n",
        "print(f\"Original Country: '{original_instance_data['Country']}'\")\n",
        "print(f\"Age: {original_instance_data['Age']:.0f}, Area Income: ${original_instance_data['Area Income']:,.2f}\")\n",
        "print(\"-\"*60)\n",
        "print(f\"True Label: {'Clicked' if true_label == 1 else 'Did Not Click'}\")\n",
        "print(f\"Model Prediction: {'Clicked' if predicted_label == 1 else 'Did Not Click'}\")\n",
        "print(f\"Predicted Probabilities: [P(Did Not Click)={prediction_probs[0][0]:.4f}, P(Clicked)={prediction_probs[0][1]:.4f}]\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate the explanation for the selected instance.\n",
        "explanation = explainer.explain_instance(\n",
        "    instance_to_explain,\n",
        "    prediction_wrapper,\n",
        "    num_features=20, # Use a big number of features for a detailed view\n",
        "    top_labels=1\n",
        ")\n",
        "\n",
        "html_explanation = explanation.as_html(show_table=True, show_all=False)\n",
        "display(HTML(html_explanation))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6.3 Appendix "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Unlike Method 6.2, here we use the one-hot tensor directly.\n",
        "# LIME will see ~300 binary columns instead of a single categorical feature.\n",
        "X_train_naive_onehot = np.hstack([\n",
        "    train_country_tensor_2d,\n",
        "    train_city_tensor_2d,\n",
        "    train_ad_seqs,\n",
        "    train_hot_tensor, # The key difference: we use the one-hot tensor\n",
        "    train_nums_tensor\n",
        "])\n",
        "print(f\"Shape of the naive one-hot training matrix for LIME: {X_train_naive_onehot.shape}\")\n",
        "\n",
        "query_feature_names_naive = [f'Query_Feature_{i}' for i in range(train_hot_tensor.shape[1])]\n",
        "feature_names_naive = (\n",
        "    country_feature_names + city_feature_names + ad_feature_names +\n",
        "    query_feature_names_naive + numeric_cols\n",
        ")\n",
        "\n",
        "# We identify all categorical features, including the ~300 for the query.\n",
        "categorical_features_indices_naive = list(range(\n",
        "    len(country_feature_names) + len(city_feature_names) +\n",
        "    len(ad_feature_names) + len(query_feature_names_naive)\n",
        "))\n",
        "\n",
        "categorical_names_naive = {}\n",
        "categorical_names_naive[feature_names_naive.index('Country')] = index_to_country\n",
        "categorical_names_naive[feature_names_naive.index('City')] = index_to_city\n",
        "for i in range(AD_MAX_LEN):\n",
        "    categorical_names_naive[feature_names_naive.index(f'Ad_Word_{i+1}')] = index_to_ad_word\n",
        "\n",
        "\n",
        "def prediction_wrapper_naive_onehot(data):\n",
        "    country_end = 1\n",
        "    city_end = country_end + 1\n",
        "    ad_end = city_end + AD_MAX_LEN\n",
        "    query_end = ad_end + train_hot_tensor.shape[1]\n",
        "    \n",
        "    model_inputs = {\n",
        "        'country_input': data[:, :country_end].astype(int),\n",
        "        'city_input': data[:, country_end:city_end].astype(int),\n",
        "        'ad_input': data[:, city_end:ad_end].astype(int),\n",
        "        'query_input': data[:, ad_end:query_end], # Pass the one-hot data directly\n",
        "        'numeric_input': data[:, query_end:]\n",
        "    }\n",
        "    return best_model.predict(model_inputs, verbose=0)\n",
        "\n",
        "explainer_naive = lime.lime_tabular.LimeTabularExplainer(\n",
        "    training_data=X_train_naive_onehot,\n",
        "    feature_names=feature_names_naive,\n",
        "    class_names=['Did Not Click', 'Clicked'],\n",
        "    categorical_features=categorical_features_indices_naive,\n",
        "    categorical_names=categorical_names_naive,\n",
        "    mode='classification',\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "instance_to_explain_naive = np.hstack([\n",
        "    test_country_tensor[instance_idx].reshape(1, -1),\n",
        "    test_city_tensor[instance_idx].reshape(1, -1),\n",
        "    test_ad_seqs[instance_idx].reshape(1, -1),\n",
        "    test_hot_tensor[instance_idx].reshape(1, -1), #We use the one-hot vector of the instance\n",
        "    test_nums_tensor[instance_idx].reshape(1, -1)\n",
        "]).flatten()\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(f\"GENERATING A NAIVE EXPLANATION FOR INSTANCE #{instance_idx}\")\n",
        "print(\"=\"*60)\n",
        "print(\"This explanation treats each one-hot column as an independent feature.\")\n",
        "\n",
        "explanation_naive = explainer_naive.explain_instance(\n",
        "    instance_to_explain_naive,\n",
        "    prediction_wrapper_naive_onehot,\n",
        "    num_features=20,\n",
        "    top_labels=1\n",
        ")\n",
        "\n",
        "html_explanation_naive = explanation_naive.as_html(show_table=True, show_all=False)\n",
        "display(HTML(html_explanation_naive))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As the explanation above demonstrates, treating the one-hot encoded `Search Query` feature naively leads to a significantly less useful result, even within a holistic framework.\n",
        "\n",
        "**Key Problems Observed:**\n",
        "1.  **Low-Level Information:** The explanation is cluttered with statements like `Query_Feature_164=0`, `Query_Feature_282=0`, etc. This tells us the impact of a specific query *not being present*, which is far less intuitive than knowing the impact of the query that *was* present. The single most important piece of information—which query was actually active—is often drowned out.\n",
        "2.  **Potential for Unrealistic Scenarios:** LIME's perturbations might have created invalid states (e.g., a sample with no query active, or multiple queries active) to train its local linear model, potentially compromising the reliability of the explanation itself.\n",
        "3. As the \"Feature | Value\" table from the explanation clearly demonstrates, the output is **flooded with low-level, uninformative features** like `Query_Feature_89=0`, `Query_Feature_0=0`, and `Query_Feature_84=0`.\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
